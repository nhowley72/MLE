{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    stock_ticker: str\n",
    "\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(request: PredictionRequest):\n",
    "    ticker = request.stock_ticker\n",
    "    \n",
    "    # Load the saved model and scaler for this ticker\n",
    "    # (Make sure the files exist; otherwise handle the error.)\n",
    "    model = joblib.load(f\"stock_price_predictor.h5\")\n",
    "\n",
    "    # 1. Fetch recent data to predict for\n",
    "    #    (Here, just as an example, let's fetch 5 days of data)\n",
    "    recent_data = fetch_stock_data(ticker, \"2023-01-01\", \"2023-01-31\")\n",
    "\n",
    "    # 2. Prepare data for prediction (matching the training logic)\n",
    "    #    This depends on how your model was trained. \n",
    "    #    If your model needs a single row, or multiple rows, etc.\n",
    "    #    For our minimal example, let's do the same single day shift trick:\n",
    "    if len(recent_data) < 2:\n",
    "        return {\"error\": \"Not enough data for prediction.\"}\n",
    "\n",
    "    # We'll take the second-to-last close to predict for the last close, etc.\n",
    "    recent_data['Close_tomorrow'] = recent_data['Close'].shift(-1)\n",
    "    recent_data.dropna(inplace=True)\n",
    "    \n",
    "    X_new = recent_data[['Close']].values\n",
    "    X_new_scaled = scaler.transform(X_new)  # scale\n",
    "\n",
    "    # 3. Predict\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "\n",
    "    # 4. Return predictions in JSON-friendly format\n",
    "    return {\n",
    "        \"stock_ticker\": ticker,\n",
    "        \"predictions\": predictions.tolist()\n",
    "    }\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"Stock Prediction API is up and running!\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ticker):\n",
    "    \n",
    "    # Load the saved model and scaler for this ticker\n",
    "    # (Make sure the files exist; otherwise handle the error.)\n",
    "    model = joblib.load(f\"stock_price_predictor.h5\")\n",
    "\n",
    "    # 1. Fetch recent data to predict for\n",
    "    #    (Here, just as an example, let's fetch 5 days of data)\n",
    "    recent_data = fetch_stock_data(ticker, \"2023-01-01\", \"2023-01-31\")\n",
    "\n",
    "    # 2. Prepare data for prediction (matching the training logic)\n",
    "    #    This depends on how your model was trained. \n",
    "    #    If your model needs a single row, or multiple rows, etc.\n",
    "    #    For our minimal example, let's do the same single day shift trick:\n",
    "    if len(recent_data) < 2:\n",
    "        return {\"error\": \"Not enough data for prediction.\"}\n",
    "\n",
    "    # We'll take the second-to-last close to predict for the last close, etc.\n",
    "    recent_data['Close_tomorrow'] = recent_data['Close'].shift(-1)\n",
    "    recent_data.dropna(inplace=True)\n",
    "    \n",
    "    X_new = recent_data[['Close']].values\n",
    "    X_new_scaled = scaler.transform(X_new)  # scale\n",
    "\n",
    "    # 3. Predict\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "\n",
    "    # 4. Return predictions in JSON-friendly format\n",
    "    return {\n",
    "        \"stock_ticker\": ticker,\n",
    "        \"predictions\": predictions.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "72",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(ticker):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Load the saved model and scaler for this ticker\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# (Make sure the files exist; otherwise handle the error.)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstock_price_predictor.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 1. Fetch recent data to predict for\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#    (Here, just as an example, let's fetch 5 days of data)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     recent_data \u001b[38;5;241m=\u001b[39m fetch_stock_data(ticker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-31\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 72"
     ]
    }
   ],
   "source": [
    "predict(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
